A exploração de conjuntos de dados é um problema abordado com frequência em computação, tanto na área acadêmica quanto na indústria~\cite{Ngai2009,Harding2006}. Tal exploração tem como objetivo uma melhor compreensão dos fenômenos que afetam a sociedade em determinados aspectos. Com base nos novos conhecimentos adquiridos, espera-se melhorar o processo de tomadas de decisões como por exemplo, previsão de condições climáticas, diagnósticos de doenças, detecções de fraude, análise de mercado, etc.

A etapa inicial da exploração consiste nas tarefas de coleta e armazenamento dos dados e pode ser realizada por sensores, sistemas de monitoramento, simulações ou aplicações diversas que utilizam banco de dados. A meta desta etapa é coletar o máximo de informação sobre um domínio e espera-se, posteriormente, extrair novos conhecimentos a partir dos dados coletados~\cite{Keim2002}. 

% Falar mais de dados redundantes e irrelevantes
Uma consequência direta de se coletar o máximo de informação é que dificilmente se conhecerá a dimensionalidade intrínseca dos dados, isto é, o conjunto de dimensões\footnote{No contexto deste documento, os termos dimensões (terminologia de mineração de dados), variáveis (terminologia estatística) e atributos (terminologia de banco de dados) são utilizados com o mesmo significado.} observadas que realmente são relevantes para a compreensão do fenômeno em estudo. Isso faz com que, em muitas vezes, se utilize todos os atributos coletados nas investigações, elevando o custo computacional e dificultando as análises. 

Quando o número de atributos utilizado nas análises é muito elevado, 50 variáveis por exemplo, há a ocorrência do problema conhecido como a  ``Maldição da Dimensionalidade''~\cite{Beyer1999}. Esta ``maldição'' refere-se ao fato de que algumas das propriedades geométricas de espaços bi ou tridimensionais não se mantém para espaços de maior dimensionalidade. Uma consequência prática de tal fato é que conforme o número de  dimensões aumenta, a distância entre um ponto e seu vizinho mais próximo tende a mesma distância deste ponto ao seu vizinho mais distante~\citet{Beyer1999}.

Ao enfrentar as dificuldades impostas pela alta dimensionalidade, uma abordagem adotada com frequência é o uso de métodos de redução de dimensionalidade. O objetivo desses métodos é encontrar o menor espaço dimensional que é capaz de descrever os dados mantendo informações que são relevantes segundo a um determinado critério. Tal abordagem é  viabilizada pelo fato de que a maioria dos conjuntos de dados possuem atributos que não são ``importantes'' para a compreensão do fenômeno observado.

A maioria dos métodos de redução de dimensionalidade são ditos métodos caixa-preta, ou seja, o usuário inspeciona apenas os dados de entrada e saída, desconhecendo o processamento realizado internamente. Deste modo, esses métodos restringem a interação do usuário, o que além de tornar o processo pouco intuitivo, impede que o usuário modifique os resultados de acordo com a sua experiência na área. 

Mas esqueça por um momento as limitações dos métodos de redução de dimensionalidade. Imagine uma situação onde todas as variáveis observadas apresentem igual e distinta importância para a compreensão do fenômeno em estudo. Ainda assim, esta situação pode não ser a ideal. Podem existir outros fatores que desempenhem papel fundamental para a compreensão do problema e que não tenham sido capturados na etapa de coleta e armazenamento dos dados. Em situações como esta, somente inserindo o conhecimento de um especialista da área no processamento dos dados será possível se compreender o fenômeno por completo. 

Deste modo, este trabalho de mestrado tem como objetivo não somente criar um método em que o usuário seja capaz de reduzir a dimensionalidade dos conjuntos de dados de forma mais intuitiva, mas também um método que permita ao usuário inserir seu conhecimento no processo. De modo que dimensões redundantes ou irrelevantes sejam descartadas e novas dimensões sejam construídas para representar o conhecimento do usuário. 

Métodos visuais que permitem a interação do usuário ganharam     grande popularidade nos últimos anos~\cite{State2012}.
Grande parte deste sucesso pode ser atribuído ao uso efetivo da  capacidade preemptiva da visão humana.
Foi demonstrado que quando os dados são representados por alguma forma gráfica, o ser humano é capaz de detectar e reconhecer     padrões facilmente e rapidamente~\cite{Healey1995}, mesmo em     grandes conjuntos de dados~\cite{Fodor2002}.
Mas a capacidade preemptiva de visão humana não é a única        vantagem dos métodos interativos. Permitir que o usuário         participe ativamente nos processos e na geração dos resultados   também traz grandes benefícios em relação a métodos              completamente automáticos.

% A área de visualização computacional é uma alternativa interessante em relação aos métodos automáticos para a  exploração de conjuntos de dados, pois permite que o usuário utilize sua percepção visual para detectar padrões e seu conhecimento sobre o domínio para orientar as análises. 

% A obtenção de conjuntos de dados concisos, ou seja, conjuntos que não contém atributos irrelevantes ou redundantes, proporcionará  uma análise mais efetiva dos dados. Por exemplo, pode se melhorar o desempenho de agrupadores e classificadores de dados. Pretende-se avaliar as contribuições deste trabalho justamente pela quantificação do desempenho de tais métodos ao utilizar as técnicas desenvolvidas, seguida de uma comparação com técnicas já estabelecidas na literatura.
